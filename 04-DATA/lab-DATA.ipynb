{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chefs-kiss/ML_J2026/blob/main/PA4_Data_Cleaning_with_AirBnB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name:\n",
        "\n",
        "Who you worked with:\n"
      ],
      "metadata": {
        "id": "RnWAlEV-vZK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n",
        "The goals of this project are to:\n",
        "- Perform EDA and data cleaning\n",
        "- Implement transformations and filtering functions\n",
        "- Look for EDA and data cleaning inspiration from outside sources\n",
        "\n",
        "## Overview\n",
        "For this programming assignment, you will practice some data cleaning and preprocessing, using a dataset of AirBNB data from New York City. In working with this dataset, our goal will be to train a model that can predict the price of an AirBNB rental. Imagine that you are a data scientist working for AirBNB, and your boss has asked you to develop this as a tool that can suggest prices for new listings.\n",
        "\n",
        "## Schedule\n",
        "Here is the suggested schedule for working on this project:\n",
        "- Weekend: Read through project instructions, complete Task 1.\n",
        "- Tuesday: Complete Tasks 2-3.\n",
        "- Wednesday: Complete Tasks 4-5.\n",
        "- Thursday: Complete Task 6.\n",
        "\n",
        "This project is due on Thursday, 3/13, by 11:59pm.\n"
      ],
      "metadata": {
        "id": "XuTSMNcdtebo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: NYC Data\n",
        "\n",
        "The data is available from a dataset from OpenML (among many other places) that contains information on multiple cities.\n"
      ],
      "metadata": {
        "id": "lJ_XAl12thEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "airbnb = fetch_openml(name=\"U.S.-Airbnb-Open-Data\", as_frame=True)\n",
        "X = airbnb['data']\n",
        "y = airbnb['target']\n",
        "airbnb_df = pd.concat([X, y], axis=1)"
      ],
      "metadata": {
        "id": "OqtNKm8vgayB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üíª Q1: NYC Data Only\n",
        "\n",
        "Your first task is to create a subset dataframe called `nyc` that filters down to only records where the city is New York City.\n",
        "\n",
        "The format for this is:\n",
        "```\n",
        "selection = df[col] == thing\n",
        "subset_df = df[selection]\n",
        "```\n",
        "or you can condense this down to\n",
        "```\n",
        "subset_df = df[df[col] == thing]\n",
        "```\n",
        "where `thing` is what you're filtering on, and `df` is the original dataframe\n",
        "\n",
        "You will need to update the code chunk below and replace `df`, `col` and `thing` with the appropriate information from our dataset. Keep the `.copy(deep=True)` chained at the end. Once you're satisfied with your selections, make sure to uncomment out the line of code and run it."
      ],
      "metadata": {
        "id": "eRsGkLFdbq58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc = #df[df[col] == thing].copy(deep=True)"
      ],
      "metadata": {
        "id": "Emiz_jpigmY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the first few rows and the column names."
      ],
      "metadata": {
        "id": "72BMblXCtlEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc.head(5)"
      ],
      "metadata": {
        "id": "ibUUgX_VhATq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc.columns"
      ],
      "metadata": {
        "id": "f4B2gjDLgwNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q2: Information on Columns\n",
        "\n",
        "For each column in the dataset, write a brief description (1-2 sentences) of what it represents. There is a helpful [data dictionary](https://docs.google.com/spreadsheets/d/1b_dvmyhb_kAJhUmv81rAxl4KcXn0Pymz/edit?gid=1967362979#gid=1967362979) that is referenced on this [Kaggle site](https://www.kaggle.com/datasets/arianazmoudeh/airbnbopendata) for the dataset. Use either to help you with this step."
      ],
      "metadata": {
        "id": "IzjEhfQiU9DZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answers here]"
      ],
      "metadata": {
        "id": "greKXeZpzl0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Held-Out Set\n",
        "Now, I'm going to select a few records that we'll use at the end to test a prediction function. I'm selecting these here, since we'll be making changes to the dataset later."
      ],
      "metadata": {
        "id": "FGleSEF2y_zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_indices = range(0, 9000, 1000)\n",
        "\n",
        "held_out = nyc.iloc[chosen_indices]\n",
        "\n",
        "held_out"
      ],
      "metadata": {
        "id": "6SuuUoc3jtqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task2: Dropping Features\n",
        "\n",
        "Now, we're going to drop some of the columns from the dataset. We start by listing all of the columns from the dataframe."
      ],
      "metadata": {
        "id": "sgO_Mv92VBQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc.columns"
      ],
      "metadata": {
        "id": "IcB9jMLKuij-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We drop some of the columns here. The format is\n",
        "\n",
        "```\n",
        "df.drop(cols_to_drop, axis = 1, inplace = True)\n",
        "```\n",
        "where `df` is our dataframem, and `cols_to_drop` are the columns we decided to remove."
      ],
      "metadata": {
        "id": "5eT3lc1zz6OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = ['id', 'name', 'host_id', 'host_name', 'minimum_nights', 'last_review', 'reviews_per_month', 'availability_365']\n",
        "nyc.drop(columns = cols_to_drop, axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "BUfOR3H9vk3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc.columns"
      ],
      "metadata": {
        "id": "RPixb8KFiK_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q3: Dropping Features\n",
        "For each dropped column, explain why your think it is a reasonable or unreasonable choice to drop that column. Feel free to disagree with my choices! (Though we'll stick with my choices for this assignment.)"
      ],
      "metadata": {
        "id": "zQAQExymz83e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answers here]"
      ],
      "metadata": {
        "id": "5uuCOWLo0FDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's look at the columns we have left"
      ],
      "metadata": {
        "id": "T8N4IMhx0HHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc.columns"
      ],
      "metadata": {
        "id": "-hNyQWvmvzZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q4: Explain reasoning\n",
        "\n",
        "For each remaining column, explain why your think it is a reasonable or unreasonable choice to keep that column. Feel free to disagree with my choices!"
      ],
      "metadata": {
        "id": "rID8aSMY0LcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answers here]"
      ],
      "metadata": {
        "id": "9uPQJV5a0PIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's look at what we have left in our data."
      ],
      "metadata": {
        "id": "k-z2p1RG0Xih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "wL_sZGW4v0yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Numeric Features\n",
        "Our data cleaning and preprocessing will focus on transformations to individual features."
      ],
      "metadata": {
        "id": "_t81-qMWVHgh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Price\n",
        "\n",
        " We'll start by looking at our target, price. Let's look at a histogram, to see how the prices are distributed."
      ],
      "metadata": {
        "id": "G20CYyGDfGSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['price'].hist(bins = 80)"
      ],
      "metadata": {
        "id": "04nRzo4sVJDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is extremely skewed. We have a price that's \\$100,000, but the vast majority have a price under \\$1000.\n",
        "\n",
        "Thinking about the tool we're building, we might want to focus on training a model that predicts well for lower/typical prices, and ignore the really expensive ones. Let's look at what happens with a few different choices for restricting the prices."
      ],
      "metadata": {
        "id": "n4SRNSFh0pwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we look at prices below $2,000."
      ],
      "metadata": {
        "id": "UJSgg4U71PuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of entries: \", len(nyc[nyc['price'] < 2000]))\n",
        "\n",
        "nyc[nyc['price'] < 2000]['price'].hist(bins = 100)"
      ],
      "metadata": {
        "id": "9CRO4rTPVQ5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's look at prices below $1,000."
      ],
      "metadata": {
        "id": "IrpNRlJ_1tev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of entries: \", len(nyc[nyc['price'] < 1000]))\n",
        "\n",
        "nyc[nyc['price'] < 1000]['price'].hist(bins = 100)"
      ],
      "metadata": {
        "id": "xx_DkhQYWlTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we look at prices below $500."
      ],
      "metadata": {
        "id": "WJcNDZVf1xF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of entries: \", len(nyc[nyc['price'] < 500]))\n",
        "\n",
        "nyc[nyc['price'] < 500]['price'].hist(bins = 100)"
      ],
      "metadata": {
        "id": "UhH0BzDtXNu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's focus on prices below $500. This still captures a lot of the data, while limiting us to trying to predict prices for more typical listings. Note that the distribution is still skewed - we'll handle this in a bit."
      ],
      "metadata": {
        "id": "iQyj09uI10Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc = nyc[nyc['price'] < 500]\n",
        "\n",
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "mHsmNLCMWvkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that the minimum price is \\$0, which seems like nonsense. Let's look at the listings with a price of \\$0."
      ],
      "metadata": {
        "id": "4qs1C4T32Hni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[nyc['price'] <= 0]"
      ],
      "metadata": {
        "id": "48SBQIZ-YT4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There aren't too many of them, so let's just exclude those."
      ],
      "metadata": {
        "id": "hrxTEWcO2PLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc = nyc[nyc['price'] > 0]\n",
        "\n",
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "QQweFVPBYZi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've seen that even restricting to prices below $500, we still have a skewed distribution. Let's see if applying a transformation can help. First, we try applying a log function."
      ],
      "metadata": {
        "id": "xL0y_3rk2T8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"price\"].apply(np.log).hist(bins = 50)"
      ],
      "metadata": {
        "id": "oVzocacEXsgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also see what happens with applying a square root function."
      ],
      "metadata": {
        "id": "JeQ8P2GA2-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"price\"].apply(np.sqrt).hist(bins = 50)"
      ],
      "metadata": {
        "id": "zFSP-RxIYlvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll choose to apply the log transformation. Note that applying such a transformation does make sense here, because the difference between prices \\$400 and \\$450 is less significant than the difference between prices \\$50 and \\$100.\n",
        "\n",
        "##üíª Q5: Log Price\n",
        "Add a new column called `log_price`, which has the log transformation appied to the column `price`. Then, drop `price` from the dataframe."
      ],
      "metadata": {
        "id": "lrWDO4gH3Dzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add column log_price\n",
        "nyc[\"log_price\"] = #your code here\n",
        "\n",
        "#drop price\n",
        "#your code here\n",
        "\n",
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "K0VICYeilj2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(np.isclose(nyc[\"log_price\"].mean(), 4.60618))\n",
        "assert(\"price\" not in nyc.columns)"
      ],
      "metadata": {
        "id": "VXXl3ilM3e78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latitude and Longitude\n",
        "\n",
        "Now, let's take a look at latitude and longitude. We'll look at the maximum and mininum values, to see the range they fall in."
      ],
      "metadata": {
        "id": "mJkjsaCpct3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nyc['latitude'].max())\n",
        "print(nyc['latitude'].min())\n",
        "print(nyc['longitude'].max())\n",
        "print(nyc['longitude'].min())"
      ],
      "metadata": {
        "id": "nwzWqntxwwoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This range makes sense here, since all of the listings are in New York City. Now, let's look at histograms."
      ],
      "metadata": {
        "id": "W-hzeo8Oz-bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['latitude'].hist(bins = 50)"
      ],
      "metadata": {
        "id": "RM9eOPo9c0qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['longitude'].hist(bins = 50)"
      ],
      "metadata": {
        "id": "NY2wDv18cxwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distributions look pretty close to normal, so we'll leave them as they are."
      ],
      "metadata": {
        "id": "r_k9bMIt0Gx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of Reviews\n",
        "\n",
        "Now, let's look at number of reviews. We'll create a histogram to see the distribution of the data."
      ],
      "metadata": {
        "id": "S3qiwOuAdGk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['number_of_reviews'].hist(bins = 50)"
      ],
      "metadata": {
        "id": "ZFCKXt88c3qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This has a very dramatic right skew, so let's try applying some transformations. We'll start with a log transformation.\n",
        "\n",
        "Now, if we were to apply the log transformation to this feature we would end up with an error. To fix this we need to add 1 to each value prior to log transforming it. This process is called smoothing and can be particularly helpful when working with text data in the future.\n",
        "\n",
        "##‚úè Q6: Add one smoothing\n",
        "\n",
        "Explain why we need to add 1. Hint: are there any values that when you apply the log transformation you would run into issues?\n"
      ],
      "metadata": {
        "id": "pH5Wf5ca0js8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answer here]"
      ],
      "metadata": {
        "id": "NCyVhomst8PN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's visualize this add-one smoothing log transformation"
      ],
      "metadata": {
        "id": "xSuS22Hqt-Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"number_of_reviews\"].apply(lambda x: (np.log(x+1))).hist(bins = 50)"
      ],
      "metadata": {
        "id": "F1U9s0mreOdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an improvement, but still right skewed. Let's look at a square root transformation next."
      ],
      "metadata": {
        "id": "kuiz1bfL05jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"number_of_reviews\"].apply(np.sqrt).hist(bins = 50)"
      ],
      "metadata": {
        "id": "iEDuQEatejqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's not as good as the log transformation.\n",
        "\n",
        "Since the result of the log transformation is still pretty skewed, let's try applying the log transformation again. Again, we'll have to add 1 before applying the log transformation.\n",
        "\n",
        "##üíª Q7: log-log function\n",
        "In the cell below, define a function called `log_log` that does the following computation:\n",
        "$$ f(x) = \\log(\\log(x+1)+1)$$.\n",
        "\n",
        "Note: replace the keyword `pass` with the computation above."
      ],
      "metadata": {
        "id": "aON9IP1D1BvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_log(value):\n",
        "  pass\n",
        "\n",
        "# create histogram\n",
        "nyc[\"number_of_reviews\"].apply(log_log).hist(bins = 50)"
      ],
      "metadata": {
        "id": "BVu0-pvZfA4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This still isn't great, but we can see that we're going to have trouble improving much more, since the number of reviews is going to be very discrete for small numbers (hence the tall, isolated columns on the left side). So, we'll use the log-log transformation."
      ],
      "metadata": {
        "id": "NKaRXbL52FQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now construct a new column, `log_log_number_of_reviews`, by applying the `log_log` function to the column `number_of_reviews`. Drop the old column, `number_of_reviews`, from the data frame"
      ],
      "metadata": {
        "id": "oKbiVBzH1uuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "\n",
        "\n",
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "aDPVHMhUfNAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(\"log_log_number_of_reviews\" in nyc.columns)\n",
        "assert(\"number_of_reviews\" not in nyc.columns)\n",
        "assert(np.isclose(nyc[\"log_log_number_of_reviews\"].mean(), 0.896842))"
      ],
      "metadata": {
        "id": "-HgdXONk9XQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculated Host Listings Count\n",
        "\n",
        "Now, let's look at the column `calculated_host_listings_count`. We'll look at the distribution."
      ],
      "metadata": {
        "id": "NCb2OwNK2u_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['calculated_host_listings_count'].hist(bins = 50)"
      ],
      "metadata": {
        "id": "iV6JCj2QzcTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since this is very skewed, let's look at what happens when we apply a log transformtion."
      ],
      "metadata": {
        "id": "zoPIqIOv2-UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"calculated_host_listings_count\"].apply(np.log).hist(bins = 50)"
      ],
      "metadata": {
        "id": "4DW0rd_ag6H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still very skewed, so let's try the log log transformation"
      ],
      "metadata": {
        "id": "qqIRctLu3H-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"calculated_host_listings_count\"].apply(log_log).hist(bins = 50)"
      ],
      "metadata": {
        "id": "1WLUnwGGhEu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still skewed, and we can tell that the data becoming very discrete is going to be an issue. This might not be the best choice, but let's just stick with applying a log transformation."
      ],
      "metadata": {
        "id": "8A8IXOvN3RW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc[\"log_calculated_host_listings_count\"] = nyc[\"calculated_host_listings_count\"].apply(np.log)\n",
        "\n",
        "nyc.drop(\"calculated_host_listings_count\", axis = 1, inplace = True)\n",
        "\n",
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "Le4KflbVhU8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Categorical Features\n"
      ],
      "metadata": {
        "id": "qtP-XnCqY99V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neighborhoods\n",
        "\n",
        "Next, we'll look at the neighborhood information. We'll start by looking at neighbourhood_group."
      ],
      "metadata": {
        "id": "PwLDQtR9gbMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['neighbourhood_group'].value_counts()"
      ],
      "metadata": {
        "id": "POW3vBUWwQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are five classes here, so we'll just one hot encode them."
      ],
      "metadata": {
        "id": "xm3H0N7u4G5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbhd_gp_dummies = pd.get_dummies(nyc[\"neighbourhood_group\"], prefix = \"neighbourhood_group\")\n",
        "\n",
        "nyc = nyc.join(nbhd_gp_dummies)\n",
        "nyc.drop('neighbourhood_group', axis = 1, inplace = True)\n",
        "\n",
        "nyc.describe()"
      ],
      "metadata": {
        "id": "Eb2BmWW6ZXoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's look at the column neighbourhood."
      ],
      "metadata": {
        "id": "N741gNHG4PcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['neighbourhood'].value_counts()"
      ],
      "metadata": {
        "id": "LAXQvMnkalvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This one is more complicated. There are some very well represented classes, and some that only occur once. Our strategy will be to one-hot encode the common entries, and ignore the rest.\n",
        "\n",
        "For our threshold, we will only take entries that occur at least 1000 times. This gives us a reasonable number of entries to one-hot encode."
      ],
      "metadata": {
        "id": "gojwIibC4Wav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_nbhds = airbnb_df.groupby(\"neighbourhood\").filter(lambda x: len(x) >= 1000)['neighbourhood'].unique()\n",
        "common_nbhds"
      ],
      "metadata": {
        "id": "AdVcVb3FaERE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll group together all entries that occurred fewer than 1000 times into one group, called \"Other\". This will make it easier to handle only one-hot encoding the common entries.\n",
        "\n",
        "##üíª Q8: filter neighborhoods function\n",
        "\n",
        "To do this, we define a function to apply to the function. If the neighborhood is a common one, just return that neighborhood name. Otherwise, return \"Other\" instead."
      ],
      "metadata": {
        "id": "brL2-sHZ43Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_nbhd(neighborhood):\n",
        "  pass\n",
        "\n",
        "\n",
        "#nyc['neighbourhood'] = nyc['neighbourhood'].apply(filter_nbhd)\n",
        "\n",
        "#nyc['neighbourhood'].value_counts()"
      ],
      "metadata": {
        "id": "WMnu4dXzbTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(len(nyc['neighbourhood'].unique()) == 12)"
      ],
      "metadata": {
        "id": "hmhS6k_w5Ts_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you'll one-hot encode the column \"neighbourhood\", adding new columns with the prefix \"neighborhood\".\n",
        "\n",
        "##üíª Q9: one-hot encode neighborhoods\n",
        "\n",
        "Drop \"neighbourhood\" and \"neighbourhood_Other\" from the dataframe."
      ],
      "metadata": {
        "id": "iHYt_A_D5jwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encode neighbourhood\n",
        "# your code here\n",
        "\n",
        "\n",
        "# drop neighbourhood and neighbourhood_Other\n",
        "# your code here\n",
        "\n",
        "\n",
        "airbnb_df.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "GkoX1QVzby9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(\"neighbourhood_East Village\" in nyc.columns)\n",
        "assert(\"neighbourhood_Other\" not in nyc.columns)\n",
        "assert(\"neighbourhood\" not in nyc.columns)"
      ],
      "metadata": {
        "id": "DrDPwVBp5-3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Room Type\n",
        "\n",
        "We'll look at room type next."
      ],
      "metadata": {
        "id": "hIQomBvIf3U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nyc['room_type'].value_counts()"
      ],
      "metadata": {
        "id": "Ax52GcWzf_nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q10: Reasoning for OHE\n",
        "\n",
        "We're going to apply one-hot encoding to this feature as it is. Why are we choosing to do the OHE immediately instead of doing additional cleaning on this feature first?"
      ],
      "metadata": {
        "id": "0uyjUtMs0SpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answer here]"
      ],
      "metadata": {
        "id": "dMdS3YrWzLC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go ahead and OHE room_type"
      ],
      "metadata": {
        "id": "3EP_WrIBzMOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "room_type_dummies = pd.get_dummies(nyc[\"room_type\"], prefix = \"room_type\")\n",
        "\n",
        "nyc = nyc.join(room_type_dummies)\n",
        "nyc.drop('room_type', axis = 1, inplace = True)\n",
        "\n",
        "nyc.describe(include = \"all\")"
      ],
      "metadata": {
        "id": "b9fkEPoegDlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 5: Next Steps\n",
        "\n",
        "## Data cleaning relates to model performance\n",
        "\n",
        "Now that we have gone through our features and made some transformations, we would typically train a model to see how well it performs. Remember, data cleaning is the most impactful thing you can do to improve your model performance.\n",
        "\n",
        "The following steps would create a model to predict the price of an AirBNB rental based off our transformed feature set.\n",
        "\n",
        "Steps:\n",
        "* Selecting our features and target.\n",
        "* Split the data into testing and training sets.\n",
        "* Fit selected predictive model to the training data.\n",
        "* Check appropriate evaluation metric for our training data and for our testing data.\n",
        "* Plot predicted values again true target values, to visualize how the selected model is performing.\n",
        "\n",
        "This last step means that we will need to apply transformations to the parameters, that correspond to the transformations we did on the features of the dataset.\n",
        "\n",
        "An example for implementation with our data set:\n",
        "* Use selected model trained above to make a predict for `log_price`.\n",
        "* \"Undo\" the `log` transformation, and return the predicted price.\n",
        "* Compare your predictions to the actual prices for the records we pulled out.\n"
      ],
      "metadata": {
        "id": "2DUWmzkJuUGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q11: Next Steps\n",
        "Even after some data cleaning, suppose that we are not getting very good performance. What are two things you could try next?"
      ],
      "metadata": {
        "id": "wbp2dO0rpZYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option1:"
      ],
      "metadata": {
        "id": "ZrO1eETg8YXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option2:"
      ],
      "metadata": {
        "id": "ldI89V8hpV1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding inspiration in others\n",
        "\n",
        "The best way to learn how to clean data is to see what other people do!\n",
        "\n",
        "For this last task, scroll down and select one of the notebooks someone has published on the Kaggle site (linked in Task 1). Note: you may have to dig a bit to see one you like.\n",
        "\n",
        "Once you have a notebook selected, read through it and answer the following questions."
      ],
      "metadata": {
        "id": "gxonS7tsY9ME"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q12: Url of notebook used:\n",
        "\n",
        "[your answer here]"
      ],
      "metadata": {
        "id": "JCji2T24bPIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q13: EDA\n",
        "\n",
        "* Describe something new this workbook has done with EDA.\n",
        "* What is one reason this may be a good choice for our data.\n",
        "* What is one reason that this may not be a good choice for our data.\n",
        "* How does this compare to what we've done so far with the data?\n"
      ],
      "metadata": {
        "id": "YxR7XXq4Z6BG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answer here]"
      ],
      "metadata": {
        "id": "CEiwzI1LwH5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üíª Q14: EDA plot\n",
        "Now, try to replicate this EDA step in the code chunk below. You can copy-paste from the author's work, but you may need to change a few things so it can work on our dataframe `nyc`"
      ],
      "metadata": {
        "id": "tYFkcPyPqIir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here"
      ],
      "metadata": {
        "id": "ZD-bJKmIbmzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q15: Data Cleaning\n",
        "\n",
        "\n",
        "* Describe something new this workbook has done with data cleaning.\n",
        "* What is one reason this may be a good choice for our data.\n",
        "* What is one reason that this may not be a good choice for our data.\n",
        "* How does this compare to what we've done so far with the data?\n"
      ],
      "metadata": {
        "id": "gG5DAeHnbH89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[your answer here]"
      ],
      "metadata": {
        "id": "PN7R0FJ1wKl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üíª Q16: Data cleaning step\n",
        "Now, try to replicate this data cleaning step in the code chunk below. You can copy-paste from the author's work, but you may need to change a few things so it can work on our dataframe `nyc`"
      ],
      "metadata": {
        "id": "LLL04XjRqick"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here"
      ],
      "metadata": {
        "id": "BoGMdD8sbo0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 6: Reflection\n",
        "\n",
        "Take a moment to reflect on the assingment\n",
        "\n"
      ],
      "metadata": {
        "id": "Wrzs0k6bdijc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚úè Q17: Reflection\n",
        "\n",
        "What did you like about it? What could be improved? Your answers will not affect your overall grade. This feedback will be used to improve future programming assignments."
      ],
      "metadata": {
        "id": "byq0KKd5dkvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grading\n",
        "\n",
        "For each of the following accomplishments, there is a breakdown of points which total to 20. The fraction of points earned out of 20 will be multiplied by 5 to get your final score (e.g. 17 points earned will be 17/20 * 5 ‚Üí 4.25)\n",
        "* (1pt) Task1 q1: Correctly filters dataset\n",
        "* (2pt) Task1 q2: Gives 1-2 sectence descriptions for each feature\n",
        "* (2pt) Task2 q3: Discussed reasons for why all the listed features were dropped\n",
        "* (1pt) Task2 q4: Discussed reasons for why all the listed features were kept\n",
        "* (1pt) Task3 q5: Correctly implemented a log function\n",
        "* (1pt) Task3 q6: Identified the reason for adding 1 to each value\n",
        "* (1pt) Task3 q7: Correctly implemented a log_log with add-one function\n",
        "* (1pt) Task4 q8: Correclt implemented a filtering function for neighborhoods\n",
        "* (1pt) Task4 q9: Replicated the OHE code for neighborhoods\n",
        "* (1pt) Task4 q10: Discusses why we can do OHE without cleaning\n",
        "* (2pt) Task5 q11: Gives two scenarios to improve model performance for our airbnb dataset. Must include specific examples from the data.\n",
        "* (1pt) Task5 q12: Url of inspiration is included\n",
        "* (1pt) Task5 q13: Discusses new EDA from inspiration notebook\n",
        "* (1pt) Task5 q14: Replicates (successfully) the EDA plot\n",
        "* (1pt) Task5 q15: Discusses new data cleaning from inspiration notebook\n",
        "* (1pt) Task5 q16: Replicates (successfully) the data cleaning\n",
        "* (1pt) Task6 q17: Thoughtfully reflected on the assignment"
      ],
      "metadata": {
        "id": "Y003ChMrdmnA"
      }
    }
  ]
}